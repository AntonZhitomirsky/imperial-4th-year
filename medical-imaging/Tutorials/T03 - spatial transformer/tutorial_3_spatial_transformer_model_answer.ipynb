{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3 - Spatial transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will revisit our CNN for the MNIST classification task. This time we will integrate a spatial transformer network as learned pre-processing component in our classification network.\n",
    "\n",
    "**Objective:** Implement a spatial transformer network within a LeNet-like CNN for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Google Colab uncomment the following line to install PyTorch Lightning\n",
    "# ! pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from pytorch_lightning import LightningModule, LightningDataModule, Trainer, seed_everything\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "from torchmetrics.functional import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a [LightningDataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html) for handling the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(LightningDataModule):\n",
    "    def __init__(self, data_dir: str = './data', batch_size: int = 32, num_workers: int = 4, transform = transforms.ToTensor()):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transform        \n",
    "\n",
    "        self.test_set = MNIST(self.data_dir, train=False, transform=self.transform, download=True)\n",
    "        dev_set = MNIST(self.data_dir, train=True, transform=self.transform, download=True)\n",
    "        self.train_set, self.val_set = random_split(dev_set, [55000, 5000])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_set, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, persistent_workers=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_set, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a [LightningModule](https://lightning.ai/docs/pytorch/stable/common/lightning_module.html) for implementing the model and its training and testing steps.\n",
    "\n",
    "**Task:** Implement the missing components of the STN and change the forward pass accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(LightningModule):\n",
    "    def __init__(self, input_dim: tuple[int, int] = (28,28), output_dim: int = 10, learning_rate: float = 0.001):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        self.transformed_images = []\n",
    "        \n",
    "        # LeNet\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "            )        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16 * 4 * 4, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, self.output_dim)\n",
    "            )\n",
    "\n",
    "        # Spatial transformer network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),            \n",
    "            nn.Conv2d(4, 8, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "            )\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(8 * 4 * 4, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "            )\n",
    "\n",
    "        # Initialize the weights/bias of the last layer in regressor with identity transformation\n",
    "        self.regressor[-1].weight.data.zero_()\n",
    "        self.regressor[-1].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    # Spatial transformer network forward function\n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(x.size(0), -1)\n",
    "        theta = self.regressor(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size(), align_corners=False)\n",
    "        x = F.grid_sample(x, grid, align_corners=False)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # pass input through STN\n",
    "        xt = self.stn(x)\n",
    "        # and transformed input through standard classification CNN\n",
    "        x = self.conv(xt)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x), xt\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "    \n",
    "    def process_batch(self, batch):\n",
    "        x, y = batch\n",
    "        logits, xt = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)        \n",
    "        acc = accuracy(preds, y, task='multiclass', num_classes=self.output_dim)\n",
    "        return loss, acc, xt\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc, xt = self.process_batch(batch)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        if batch_idx == 0:\n",
    "            grid = torchvision.utils.make_grid(batch[0][0:16, ...], nrow=4, normalize=True)\n",
    "            self.logger.experiment.add_image('train_images', grid, self.global_step)\n",
    "\n",
    "            grid = torchvision.utils.make_grid(xt[0:16, ...], nrow=4, normalize=True)\n",
    "            self.logger.experiment.add_image('train_transformed_images', grid, self.global_step)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, acc, _ = self.process_batch(batch)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "\n",
    "    def on_test_start(self):\n",
    "        self.transformed_images = []\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, acc, xt = self.process_batch(batch)\n",
    "        self.log('test_loss', loss)\n",
    "        self.log('test_acc', acc)\n",
    "        self.transformed_images.append(xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the PyTorch Lightning [Trainer](https://lightning.ai/docs/pytorch/stable/common/trainer.html) for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42, workers=True)\n",
    "\n",
    "data = MNISTDataModule(data_dir='./data', batch_size=32)\n",
    "\n",
    "model = ImageClassifier(input_dim=(28,28), output_dim=10, learning_rate=0.001)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator='auto',\n",
    "    devices=1,\n",
    "    logger=TensorBoardLogger(save_dir='./lightning_logs/classification/', name='mnist-lenet-with-stn'),\n",
    "    callbacks=[ModelCheckpoint(monitor='val_loss', mode='min'), TQDMProgressBar(refresh_rate=10)],\n",
    ")\n",
    "trainer.fit(model=model, datamodule=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained model with the best checkpoint on the validation data and report the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.validate(model=model, datamodule=data, ckpt_path=trainer.checkpoint_callback.best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the trained model with the best checkpoint on the test data and report the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=model, datamodule=data, ckpt_path=trainer.checkpoint_callback.best_model_path)\n",
    "test_samples_transformed = model.transformed_images[0][0:16,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on out-of-distribution data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we prepare an out-of-distribution test set where all digits are shifted by two pixels. We then test the trained model and report the classification accuracy.\n",
    "\n",
    "**Task:** Compare the performance of the LeNet-like CNN with and without the STN component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop((26,26)),\n",
    "    transforms.Pad((0,0,2,2)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_ood = MNISTDataModule(data_dir='./data', batch_size=32, transform=transform)\n",
    "\n",
    "trainer.test(model=model, datamodule=data_ood, ckpt_path=trainer.checkpoint_callback.best_model_path)\n",
    "test_samples_ood_transformed = model.transformed_images[0][0:16,...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the original, in-distribution and the out-of-distribution test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_iid = [data.test_set[i][0] for i in range(0,16)]\n",
    "samples_ood = [data_ood.test_set[i][0] for i in range(0,16)]\n",
    "grid_iid = torchvision.utils.make_grid(samples_iid, nrow=4, normalize=True).numpy()[0,...].squeeze()\n",
    "grid_ood = torchvision.utils.make_grid(samples_ood, nrow=4, normalize=True).numpy()[0,...].squeeze()\n",
    "\n",
    "f, ax = plt.subplots(1,3, figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(grid_iid, cmap=matplotlib.cm.gray)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('in-distribution')\n",
    "\n",
    "ax[1].imshow(grid_ood, cmap=matplotlib.cm.gray)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('out-of-distribution')\n",
    "\n",
    "ax[2].imshow(grid_iid - grid_ood, cmap=matplotlib.cm.bwr)\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the original and the transformed test data when using a spatial transformer network within a classification CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_iid = [data.test_set[i][0] for i in range(0,16)]\n",
    "grid_original = torchvision.utils.make_grid(samples_iid, nrow=4, normalize=True).numpy()[0,...].squeeze()\n",
    "grid_transformed = torchvision.utils.make_grid(test_samples_transformed.cpu(), nrow=4, normalize=True).numpy()[0,...].squeeze()\n",
    "\n",
    "f, ax = plt.subplots(1,3, figsize=(15, 15))\n",
    "\n",
    "ax[0].imshow(grid_original, cmap=matplotlib.cm.gray)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('in-distribution - original')\n",
    "\n",
    "ax[1].imshow(grid_transformed, cmap=matplotlib.cm.gray)\n",
    "ax[1].axis('off')\n",
    "ax[1].set_title('in-distribution - transformed')\n",
    "\n",
    "ax[2].imshow(grid_original - grid_transformed, cmap=matplotlib.cm.bwr)\n",
    "ax[2].axis('off')\n",
    "ax[2].set_title('difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the patterns that the single-layer network has learned for each digit class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.conv[0].weight.detach().cpu().numpy()\n",
    "\n",
    "f, ax = plt.subplots(1,6, figsize=(15, 15))\n",
    "\n",
    "for i in range(0,6):\n",
    "    vmax = np.max(np.abs(weights[i,:])) / 2\n",
    "    ax[i].imshow(weights[i,:].reshape(5,5), cmap=matplotlib.cm.bwr, clim=(-vmax,vmax))\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir './lightning_logs/classification/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mli-tutorials",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
