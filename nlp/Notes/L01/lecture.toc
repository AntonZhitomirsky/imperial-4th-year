\babel@toc {english}{}\relax 
\contentsline {section}{\numberline {1}Dealing with natural language}{3}{section.2}%
\contentsline {subsection}{\numberline {1.1}Complexities}{3}{subsection.3}%
\contentsline {subsection}{\numberline {1.2}The role of Deep Learning}{3}{subsection.4}%
\contentsline {subsection}{\numberline {1.3}Composites of Language}{3}{subsection.5}%
\contentsline {subsubsection}{\numberline {1.3.1}Lexicon - morphological analysis}{3}{subsubsection.6}%
\contentsline {subsubsection}{\numberline {1.3.2}Syntax}{4}{subsubsection.14}%
\contentsline {subsubsection}{\numberline {1.3.3}Semantics}{4}{subsubsection.15}%
\contentsline {subsubsection}{\numberline {1.3.4}Discourse}{5}{subsubsection.16}%
\contentsline {subsubsection}{\numberline {1.3.5}Pragmatics}{5}{subsubsection.17}%
\contentsline {section}{\numberline {2}Word Representation}{5}{section.18}%
\contentsline {subsection}{\numberline {2.1}One-hot-encoding}{5}{subsection.19}%
\contentsline {subsubsection}{\numberline {2.1.1}Issues}{5}{subsubsection.20}%
\contentsline {subsection}{\numberline {2.2}WordNet}{6}{subsection.21}%
\contentsline {subsubsection}{\numberline {2.2.1}Issues}{6}{subsubsection.22}%
\contentsline {subsection}{\numberline {2.3}Word Embedding}{6}{subsection.23}%
\contentsline {subsubsection}{\numberline {2.3.1}Euclidean Distance}{6}{subsubsection.24}%
\contentsline {subsubsection}{\numberline {2.3.2}Cosine Distance}{6}{subsubsection.26}%
\contentsline {section}{\numberline {3}Algorithm - Word2Vec}{6}{section.28}%
\contentsline {subsection}{\numberline {3.1}Window}{6}{subsection.29}%
\contentsline {subsection}{\numberline {3.2}Continuous bag-of-words}{7}{subsection.32}%
\contentsline {subsection}{\numberline {3.3}Skip-gram}{7}{subsection.34}%
\contentsline {subsubsection}{\numberline {3.3.1}Training}{8}{subsubsection.42}%
\contentsline {subsubsection}{\numberline {3.3.2}Loss}{9}{subsubsection.44}%
\contentsline {subsubsection}{\numberline {3.3.3}Using Word Embeddings}{9}{subsubsection.46}%
\contentsline {subsubsection}{\numberline {3.3.4}Softmax problem}{10}{subsubsection.47}%
\contentsline {subsubsection}{\numberline {3.3.5}Negative Sampling}{10}{subsubsection.48}%
\contentsline {subsubsection}{\numberline {3.3.6}Size of k?}{10}{subsubsection.51}%
\contentsline {subsubsection}{\numberline {3.3.7}Noise Distribution}{10}{subsubsection.52}%
\contentsline {section}{\numberline {4}What can we do with vectors?}{11}{section.53}%
\contentsline {section}{\numberline {5}Byte Pair Encoding}{11}{section.57}%
\contentsline {subsection}{\numberline {5.1}How to represent end of word}{13}{subsection.70}%
\contentsline {subsubsection}{\numberline {5.1.1}Why?}{13}{subsubsection.71}%
\contentsline {subsection}{\numberline {5.2}Unknown words (from seen vocabulary)}{13}{subsection.72}%
\contentsline {subsection}{\numberline {5.3}Alternatives}{14}{subsection.81}%
